---
title: "Arkesh Das CMSE 410 Semester Project"
author: "Arkesh Das"
date: "03/30/2025"
output:
  pdf_document:
    latex_engine: xelatex
    keep_tex: true
    includes:
      in_header: preamble.tex
fontsize: 12pt
mainfont: Times New Roman
monofont: Courier New
linestretch: 2
---
# Applying different methods of controlling the False Discovery Rate to 

## Background 

### What is GWAS and FDR

### Et al

The data that I have chosen to analyze comes from a study that is part of Milieu Intérieur the project [1]. The Milieu Intérieur Project aims at 

Study Cohort (Milieu Intérieur)
Participants: 1000 healthy adults (500 men, 500 women), ages 20–69 (200 per decade).
Geographic/Ancestral Background: All had self-reported Metropolitan French origin (parents and grandparents born in continental France) to minimize genetic substructure.
Health Status: Individuals were stringently screened (e.g., no chronic infections, no ongoing hepatitis B/C, HIV-negative).
Sample Collection and Measurements
Blood Draw: Peripheral blood was collected into tubes containing lithium heparin (for plasma-based assays) and EDTA (for DNA extraction).
Immunoglobulin Measurements:
Total IgG, IgM, IgA, and IgE were measured from serum/plasma using clinical-grade turbidimetric tests.
Pathogen-Specific IgG: They assayed 15 different antigens from common viruses and bacteria (e.g., CMV, EBV, HSV-1/2, VZV, H. pylori, T. gondii, influenza A) plus vaccine-related antigens (measles, mumps, rubella, and hepatitis B). Each was measured via clinical-grade serologies, yielding both a seropositivity status and (for positives) a quantitative IgG level.
Genotyping and Genetic Analysis
Arrays: DNA was genotyped using (1) the Illumina HumanOmniExpress-24 (for ~700k SNPs) and (2) the HumanExome-12 (for ~245k exonic variants).
Imputation and Quality Control: The authors imputed to a reference panel (Haplotype Reference Consortium), resulting in ~5 million common variants for genome-wide association tests. They also analyzed variation in the HLA region (including HLA alleles and amino-acid positions) and KIR genes.
What They Were Looking For
Primary Goal: Understand the variability in humoral immune responses (who tests positive for each antigen, and at what antibody levels) and assess how age, sex, and host genetics (especially in the HLA region) shape these differences.
Analyses:
Logistic regressions for seropositivity (positive vs. negative).
Linear regressions for log-transformed antibody levels among seropositive donors.
Associations were tested genome-wide, with corrections for false discovery and potential confounders (age, sex, and other covariates).
Key Findings (High-Level)
Age and Sex: Strong predictors of whether a person was seropositive and at what level of IgG. Generally, older donors and women had higher rates of positivity and/or higher antibody titers for many antigens.
Genetics: Variants in the HLA class II region were significantly associated with IgG levels to EBV and rubella. Certain KIR–HLA combinations associated with total IgA levels.

# Loading in the Data

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message= FALSE, warning=TRUE)
knitr::opts_chunk$set(fig.width=12, fig.height=8) 

library(tidyverse)
library(tidyr)
library(dplyr)
library(ggplot2)
library(qqman)
library(mutoss)
library(qvalue)
```

# Reading in the Data and making dataframes

```{r dataframes}

#df will contain all of the data from the study that had MAF > 5%
#df2 is 1,000 snps, used to test code chunks before running on larger data frames
#df3 contains 100,000 random snps, used as an analogue for the entire data set
#ch6 contains the 354095 snps identified on chromosome 6

#reloading the 'df' dataframe takes a long time because of the number of observations 
df <- read.table("/Users/arkeshdas/Documents/CMSE 410/repos/HBV_HBc_GWAS_serostatus.txt", header = FALSE, sep = "", stringsAsFactors = FALSE)
colnames(df) <- c("#CHROM", "POS", "ID", "REF", "ALT", "ALT_FREQ", "TEST", "OBS_CT", "OR", "SE", "T_STAT", "P")
head(df)

df2 <- read.table("/Users/arkeshdas/Documents/CMSE 410/repos/HBV_HBc_GWAS_serostatus.txt", header = FALSE, sep = "", stringsAsFactors = FALSE, nrows = 1000)
colnames(df2) <- c("#CHROM", "POS", "ID", "REF", "ALT", "ALT_FREQ", "TEST", "OBS_CT", "OR", "SE", "T_STAT", "P")
head(df2)

set.seed(03302025)  # Setting seed for reproducibility for df3
df3 <- df[sample(nrow(df), 100000), ]
colnames(df3) <- c("#CHROM", "POS", "ID", "REF", "ALT", "ALT_FREQ", "TEST", "OBS_CT", "OR", "SE", "T_STAT", "P")
head(df3)

ch6 <- df %>% filter(`#CHROM` == 6)

colnames(ch6) <- c("#CHROM", "POS", "ID", "REF", "ALT", "ALT_FREQ", "TEST", "OBS_CT", "OR", "SE", "T_STAT", "P")
head(ch6)

df_clean <- df %>%
  filter(!is.na(P))

```

# Creating Manhattan Plots

Because I will be making many Manhattan plots, I initially decided to create a function that I can pass parameters into rather than creating a Manhattan plot by hand each time.

```{r manhattan plot function}
generate_manhattan_plot <- function(df, 
                                    chrom_col = "#CHROM", 
                                    pos_col = "POS", 
                                    pval_col = "P", 
                                    plot_title = "Manhattan Plot", 
                                    pval_cutoff = 0.05) {

  # Step 1: Normalize CHR and BP
  df <- df %>%
    mutate(CHR = gsub("chr", "", .data[[chrom_col]], ignore.case = TRUE),
           CHR = gsub("[^0-9XYMT]", "", CHR),
           CHR = as.character(CHR),
           BP = as.numeric(.data[[pos_col]])) %>%
    filter(!is.na(BP) & !is.na(CHR))

  # Step 2: Sort
  df <- df %>% arrange(as.numeric(CHR), BP)

  # Step 3: Chromosome summary
  df_chr <- df %>%
    group_by(CHR) %>%
    summarise(max_bp = max(BP, na.rm = TRUE), .groups = "drop") %>%
    arrange(as.numeric(CHR)) %>%
    mutate(cumulative = cumsum(max_bp) - max_bp)

  # Step 4: Merge
  df <- df %>%
    left_join(df_chr, by = "CHR") %>%
    filter(!is.na(cumulative)) %>%
    mutate(BP_cum = BP + cumulative)

  # Step 5: Axis labels
  axis_df <- df %>%
    group_by(CHR) %>%
    summarise(center = (min(BP_cum) + max(BP_cum)) / 2, .groups = "drop")

  # Step 6: Color map
  chroms <- sort(unique(df$CHR))
  chrom_colors <- rep(c("grey", "skyblue"), length.out = length(chroms))
  names(chrom_colors) <- chroms

  # Step 7: Manhattan Plot
  ggplot(df, aes(x = BP_cum, y = -log10(.data[[pval_col]]))) +
    geom_point(aes(color = CHR), alpha = 0.75, size = 1.3) +
    scale_color_manual(values = chrom_colors) +
    scale_x_continuous(label = axis_df$CHR, breaks = axis_df$center) +
    labs(x = "Chromosome", 
         y = expression(-log[10](p-value)), 
         title = plot_title) +
    geom_hline(yintercept = -log10(pval_cutoff), linetype = "dashed", color = "red") +
    theme_minimal() +
    theme(legend.position = "none",
          panel.border = element_blank(),
          panel.grid.major.x = element_blank())
}

```

```{r testing function}
generate_manhattan_plot(df3, pval_cutoff = 0.05, plot_title = "Manhattan Plot of Raw P-values for 100,000 SNPs")
```

However, after doing some research, I learned there are already existing functions that create Manhattan plots (`qqman` library), so I will be using this function to create my Manhattan plots instead [2].

```{r qqman 100k Bonferroni}
df3_clean <- df3 %>%
  filter(!is.na(P))
manhattan(df3_clean, chr = "#CHROM", bp = "POS", snp = "ID", p = "P", suggestiveline = FALSE,
          genomewideline = -log10(2.7e-09), ylim = c(0, 10)) 
title(main = "Manhattan Plot of Raw P-values for 100,000 SNPs Bonferroni")
abline(h = -log10(9.5e-09), col = "darkgreen", lty = 3)

```

```{r qqman ch6 0.05}

ch6_clean <- ch6 %>%
  filter(!is.na(P))
manhattan(ch6_clean, chr = "#CHROM", bp = "POS", snp = "ID", p = "P", highlight = "rs4254998",
          genomewideline = -log10(0.05), ylim = c(0, 6)) 
title(main = "Manhattan Plot of Raw P-values for Chr. 6 SNPs p = 0.05")
```
# QQ plots

I tried to create my code to create a QQ plot before I realzed that there already is one in `qqman`

```{r QQ plot for subset}
pvals <- df3$P
pvals <- pvals[!is.na(pvals)]

n <- length(pvals)

expected <- -log10(ppoints(n))
observed <- -log10(sort(pvals))

plot(expected, observed,
     pch = 19,
     col = rgb(0, 0, 0, 0.5),
     cex = 0.6,
     xlab = "Expected -log10(p)",
     ylab = "Observed -log10(p)",
     main = "QQ Plot of GWAS P-values")

abline(0, 1, col = "red", lwd = 2)


```

```{r qqplot 100k}
qq(df3_clean$P, main = "QQ Plot of GWAS P-values for 100k SNPs")
```

```{r qqplot chr6}
qq(ch6_clean$P, main = "QQ Plot of GWAS P-values for Chr. 6")
```

# Various FDR methods

Now I will be trying different FDR methods, from most to least conservative.

## Benjamini-Yekutieli

Out of the p-value adjustment methods, Benjamini Yekuteli is the most conservative, so I will try it first. R has a `p.adjust` function that can automatically apply the BY method.

```{r Benjamini-Yekutieli test}

df3_clean$P_BY <- p.adjust(df3_clean$P, method = "BY")

# Summary stats of BY-adjusted p-values
summary(df3_clean$P_BY)

# Filter significant results under BY 
df3_by_sig <- df3_clean %>% filter(P_BY < 0.05)

manhattan(df3_clean, chr = "#CHROM", bp = "POS", snp = "ID", p = "P_BY", suggestiveline = FALSE, ylim = c(0,1)) 
title(main = "Manhattan Plot of BY adjusted P-values for 100,000 SNPs")
```

I cannot visualize the BY-adjusted p-values using my Manhattan Plot. In this case, I can thankfully modify and re-use my plotting function from earlier:

```{r plot function}
generate_plot <- function(df, 
                                    chrom_col = "#CHROM", 
                                    pos_col = "POS", 
                                    pval_col = "P", 
                                    plot_title = "Plot") {

  # Step 1: Normalize CHR and BP
  df <- df %>%
    mutate(CHR = gsub("chr", "", .data[[chrom_col]], ignore.case = TRUE),
           CHR = gsub("[^0-9XYMT]", "", CHR),
           CHR = as.character(CHR),
           BP = as.numeric(.data[[pos_col]])) %>%
    filter(!is.na(BP) & !is.na(CHR))

  # Step 2: Sort
  df <- df %>% arrange(as.numeric(CHR), BP)

  # Step 3: Chromosome summary
  df_chr <- df %>%
    group_by(CHR) %>%
    summarise(max_bp = max(BP, na.rm = TRUE), .groups = "drop") %>%
    arrange(as.numeric(CHR)) %>%
    mutate(cumulative = cumsum(max_bp) - max_bp)

  # Step 4: Merge
  df <- df %>%
    left_join(df_chr, by = "CHR") %>%
    filter(!is.na(cumulative)) %>%
    mutate(BP_cum = BP + cumulative)

  # Step 5: Axis labels
  axis_df <- df %>%
    group_by(CHR) %>%
    summarise(center = (min(BP_cum) + max(BP_cum)) / 2, .groups = "drop")

  # Step 6: Color map
  chroms <- sort(unique(df$CHR))
  chrom_colors <- rep(c("grey", "skyblue"), length.out = length(chroms))
  names(chrom_colors) <- chroms

  # Step 7: Plot
  ggplot(df, aes(x = BP_cum, y = .data[[pval_col]])) +
    geom_point(aes(color = CHR), alpha = 0.75, size = 1.3) +
    scale_color_manual(values = chrom_colors) +
    scale_x_continuous(label = axis_df$CHR, breaks = axis_df$center) +
    ylim(0,0.007)+
    labs(x = "Chromosome", 
         y = 'p-value', 
         title = plot_title) +
    theme_minimal() +
    theme(legend.position = "none",
          panel.border = element_blank(),
          panel.grid.major.x = element_blank())
}

```

```{r BY plot test}
generate_plot(df3_clean, pval_col = "P_BY", plot_title = "Plot of BY adjusted P-values for 100,000 SNPs")
```

Using my new and improved plotting function, we can see that because the Benjamini-Yekutieli method is so conservative, all of the p-values were adjusted to 1.

## Benjamini-Hochberg

Now I will try adjust my p-values using the Benjamini-Hochberg method.

```{r Benjamini-Hochberg test}
# Adjusting p_values using BH
df3_clean$P_BH <- p.adjust(df3_clean$P, method = "BH")

#Summary stats of adjusted p-values
summary(df3_clean$P_BH)

df3_bh_sig <- df3_clean %>% filter(P_BH < 0.05) #there are no significant p-values after BH adjustment 
df3_clean$log10_P_BH <- -log10(df3_clean$P_BH)

manhattan(df3_clean, chr = "#CHROM", bp = "POS", snp = "ID", p = "P_BH", suggestiveline = FALSE, ylim = c(0, 0.005)) 
title(main = "Plot of BH adjusted P-values for 100,000 SNPs")


```


```{r BH plot test}
generate_plot(df3_clean, pval_col = "P_BH", plot_title = "Plot of BH adjusted P-values for 100,000 SNPs")
```

## Benjamini-Krieger-Yekutieli 

Now I will try to use the Benjamini-Krieger-Yekutieli method in the `mutoss` package [3]: 
```{r mutoss BKY, eval = FALSE}
mutoss::loadMethod("BKY")


bky_result <- mutoss::runMethod("BKY", list(pValues = df3_clean$P, alpha = 0.05))
```

Unfortunately, I could not get the `mutoss` package's implementation of BKY to work, so I will instead follow the original 2006 paper [4], which describes how to implement the BKY method:

```{r BKY implementation}
#BYK function
bky_adjust <- function(p, alpha = 0.05) {
  m <- length(p)
  p_order <- order(p)
  p_sorted <- p[p_order]
  k <- m:1
  c_m <- sum(1 / (1:m))
  
  thresh <- (k / m) * (alpha / (1 + alpha)) * (1 / c_m)
  test <- p_sorted <= thresh
  max_k <- if (any(test)) max(which(test)) else 0
  
  adjusted <- rep(1, m)
  if (max_k > 0) {
    adjusted[p_order[1:max_k]] <- pmin(1, thresh[max_k])
  }
  
  return(adjusted)
}

# Applying BKY to the data

df3_clean$P_BKY <- bky_adjust(df3_clean$P, alpha = 0.05)
df3_bky_sig <- df3_clean %>% filter(P_BKY < 0.05)

summary(df3_bky_sig$P_BKY)

# Plot
manhattan(df3_clean, chr = "#CHROM", bp = "POS", snp = "ID", p = "P_BKY",
          suggestiveline = FALSE)
title(main = "Plot of BKY Adjusted P-values for 100,000 SNPs")

```

```{r BYK plot test}
generate_plot(df3_clean, pval_col = "P_BKY", plot_title = "Plot of BH adjusted P-values for 100,000 SNPs")
```
This time, I was able to isolate around 300 significant SNPs using the BYK method. However, they were all the same p-value. Therefore, while BYK is able to separate  
## Storey-Tibshirani (q-value)

Now I will be adjusting my p-values using the Storey-Tibshirani method. Thankfully, there is a package in R that was designed in collaboration with the creators of this method, the `qvalue` package. I followed the documentation of the `qvalue` package to use the `qvalue()` method and other methods on my data [6].

```{r}
qobj <- qvalue(p = df3_clean$P)  # estimating pi_0 and q-values
df3_clean$q_value <- qobj$qvalues

df3_q_sig <- df3_clean %>% filter(q_value < 0.05)
nrow(df3_q_sig)  

qobj$pi0

```

Unfortunately, I was not able to actually find any significant q_values. My pi_0 was 0.971, which means that 97.1% of the tested SNPs are estimated to be null.

```{r best BKYs}
top_bky <- df3_clean %>%
  arrange(P) %>%
  slice(1:50) %>%
  select(`#CHROM`, POS, ID, P, P_BKY)

```

Taking a second look at the p-values that were marked as being signficant from BYK, they appear to be randomly clustered throughout the genome. However, the second most significant SNP is located on chromosome 6, the same chromosome as the HLA gene cluster that was found to be significant in the original study. So, I think to conclude, I will try to figure out where this SNP is located and its potential biological function.

SNP POS: 129948488
#CHROM: 6

I used the NCBI Human Genome Data Viewer [7] to figure out the genomic context of chr6:129948488. This SNP lies within an intron region of L3MBTL3, situated between a nearby HLA class II gene and an uncharacterized gene. L3MBTL3  has been implicated in several GWAS as influencing hematopoietic traits and immunoglobulin A (IgA) levels. Variants in L3MBTL3 have been associated with natural variation in IgA concentrations, suggesting a potential role in humoral immune regulation. These findings suggest that SNPs in or near L3MBTL3 could indirectly modulate immune responses, potentially by influencing the development or regulation of immune effector cells [8].

Therefore, while I was not able to identify a clear enrichment of significant SNPs in known immune loci across the genome, I was able to pinpoint at least one biologically plausible candidate. Its proximity to the HLA region and its known association with immune-related traits make it a promising lead for further investigation. Further analysis of the SNPs that were flagged as being significant by the BKY method should be looked into, as they may represent novel loci of biological relevance that have not yet been characterized in the context of immune response by the original study.


#Misc graphs


```{r normal distribution testing}
df3_clean$logP <- -log10(df3_clean$P)


ggplot(df3_clean, aes(x = -log10(P))) +
  geom_histogram(bins = 50, fill = "skyblue", color = "white") +
  labs(title = "Distribution of –log10(P-values)",
       x = "–log10(P-value)", y = "Count") +xlim(0, 4) 
  theme_minimal()


ggplot(df3_clean, aes(x = -log10(P))) +
  geom_histogram(bins = 50, fill = "skyblue", color = "white") +
  labs(title = "Distribution of –log10(P-values)",
       x = "–log10(P-value)", y = "Count") +xlim(2, 4) 
  theme_minimal()

```

```{r normal dist curve}
#To create figure in slide deck
x <- seq(-4, 4, length.out = 1000)
y <- dnorm(x)

df_norm <- data.frame(x = x, y = y)

z_cutoff <- qnorm(0.95)  

shade_df <- subset(df_norm, x > z_cutoff)


ggplot(df_norm, aes(x, y)) +
  geom_line(color = "black", size = 1) +  # Normal curve
  geom_area(data = shade_df, aes(x, y), fill = "skyblue", alpha = 0.6) + 
  geom_vline(xintercept = z_cutoff, color = "red", linetype = "dashed", size = 1) +  
  labs(
    title = "Standard Normal Distribution with One-Sided p = 0.05 Cutoff",
    x = "Z-score",
    y = "Density"
  ) +
  theme_minimal()

```

# References

[1] https://www.milieuinterieur.fr/en/about-us/the-milieu-interieur/

[2] https://www.rdocumentation.org/packages/qqman/versions/0.1.2/topics/manhattan

[3] https://search.r-project.org/CRAN/refmans/mutoss/html/multiple.down.html

[4] Benjamini, Y., Krieger, A. M., & Yekutieli, D. (2006). Adaptive Linear Step-up Procedures That Control the False Discovery Rate. Biometrika, 93(3), 491–507. https://doi.org/10.1093/biomet/93.3.491 

[5] Storey JD, Tibshirani R. Statistical significance for genomewide studies. Proc Natl Acad Sci U S A. 2003 Aug 5;100(16):9440-5. doi: 10.1073/pnas.1530509100. Epub 2003 Jul 25. PMID: 12883005; PMCID: PMC170937.

[6] https://www.rdocumentation.org/packages/qvalue/versions/2.4.2/topics/qvalue

[7] https://www.ncbi.nlm.nih.gov/gdv/

[8] Arai S, Miyazaki T. Impaired maturation of myeloid progenitors in mice lacking novel Polycomb group protein MBT-1. EMBO J. 2005 May 18;24(10):1863-73. doi: 10.1038/sj.emboj.7600654 
