---
title: "Arkesh Das CMSE 410 Semester Project"
author: "Arkesh Das"
date: "03/30/2025"
output:
  pdf_document:
    latex_engine: xelatex
    keep_tex: true
    includes:
      in_header: preamble.tex
fontsize: 12pt
mainfont: Times New Roman
monofont: Courier New
linestretch: 2
---
# Assessing the Influence of False Discovery Rate Methods on Genetic Associations in an Immune Response GWAS

## Background 

Genome-wide association studies (GWAS) have emerged as powerful tools for linking genetic variants with complex traits, including immune responses. A typical GWAS involves testing millions of single nucleotide polymorphisms (SNPs) for associations, which leads to a substantial multiple testing burden. Applying a simple p-value threshold (e.g., 0.05) is inadequate, as it would generate many false positives. Thus, false discovery rate (FDR) control has become an essential strategy to address this challenge.


## About the data

This project utilizes data from the Milieu Intérieur (MI) project, a comprehensive, population-based study coordinated by Prof. Lluis Quintana-Murci and Dr. Darragh Duffy at Institut Pasteur in Paris. Established under the French Government's Investissement d'Avenir – Laboratoire d’Excellence (LabEx) initiative, the MI project aims to dissect the interplay between genetics, environment, and immune variation [1]. 

It was designed to address a critical discrepancy in medicine: while immune responses vary widely among individuals, medical care and therapeutic strategies are often standardized across populations.

 I chose to use this dataset because it offers a unique opportunity to evaluate the impact of false discovery rate methods on GWAS results in the context of immune variation, and the data is high-resolution and well-characterized so it’s ideal for benchmarking statistical methods.

The data was accessed from the NHGRI-EBI GWAS Catalog. The Catalog is a publicly available repository of SNP-trait associations identified in published GWAS studies. It provides standardized annotations, p-values, effect sizes, and sample information for millions of SNPs across hundreds of phenotypes. 

The MI cohort consists of 1,000 healthy individuals, age- and sex-stratified across five decades (ages 20–70), and of french origin. Detailed serological data were collected, including total levels of IgA, IgE, IgG, and IgM, along with antibody responses to 15 antigens from common infectious agents and vaccines (e.g., influenza, EBV, CMV, HSV, rubella). The cohort was genotyped for over 700,000 SNPs and subsequently imputed to yield over 12 million genetic variants. Extensive phenotypic, demographic, clinical, and environmental metadata are also available, including vaccine history, infection exposure, CRP levels, lipid profiles, and lifestyle factors [2]. 

# Loading in the Data

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message= FALSE, warning=TRUE)
knitr::opts_chunk$set(fig.width=12, fig.height=8) 

library(tidyverse)
library(tidyr)
library(dplyr)
library(ggplot2)
library(qqman)
library(mutoss)
library(qvalue)
```

# Reading in the Data and making dataframes

```{r dataframes}

#df will contain all of the data from the study that had MAF > 5%
#df2 is 1,000 snps, used to test code chunks before running on larger data frames
#df3 contains 100,000 random snps, used as an analogue for the entire data set
#ch6 contains the 354095 snps identified on chromosome 6

#reloading the 'df' dataframe takes a long time because of the number of observations 
df <- read.table("/Users/arkeshdas/Documents/CMSE 410/repos/HBV_HBc_GWAS_serostatus.txt", header = FALSE, sep = "", stringsAsFactors = FALSE)
colnames(df) <- c("#CHROM", "POS", "ID", "REF", "ALT", "ALT_FREQ", "TEST", "OBS_CT", "OR", "SE", "T_STAT", "P")
head(df)

df2 <- read.table("/Users/arkeshdas/Documents/CMSE 410/repos/HBV_HBc_GWAS_serostatus.txt", header = FALSE, sep = "", stringsAsFactors = FALSE, nrows = 1000)
colnames(df2) <- c("#CHROM", "POS", "ID", "REF", "ALT", "ALT_FREQ", "TEST", "OBS_CT", "OR", "SE", "T_STAT", "P")
head(df2)

set.seed(03302025)  # Setting seed for reproducibility for df3
df3 <- df[sample(nrow(df), 100000), ]
colnames(df3) <- c("#CHROM", "POS", "ID", "REF", "ALT", "ALT_FREQ", "TEST", "OBS_CT", "OR", "SE", "T_STAT", "P")
head(df3)

ch6 <- df %>% filter(`#CHROM` == 6)

colnames(ch6) <- c("#CHROM", "POS", "ID", "REF", "ALT", "ALT_FREQ", "TEST", "OBS_CT", "OR", "SE", "T_STAT", "P")
head(ch6)

df_clean <- df %>%
  filter(!is.na(P))

```

# Creating Manhattan Plots

Because I will be making many Manhattan plots, I initially decided to create a function that I can pass parameters into rather than creating a Manhattan plot by hand each time.

```{r manhattan plot function}
generate_manhattan_plot <- function(df, 
                                    chrom_col = "#CHROM", 
                                    pos_col = "POS", 
                                    pval_col = "P", 
                                    plot_title = "Manhattan Plot", 
                                    pval_cutoff = 0.05) {

  # Step 1: Normalize CHR and BP
  df <- df %>%
    mutate(CHR = gsub("chr", "", .data[[chrom_col]], ignore.case = TRUE),
           CHR = gsub("[^0-9XYMT]", "", CHR),
           CHR = as.character(CHR),
           BP = as.numeric(.data[[pos_col]])) %>%
    filter(!is.na(BP) & !is.na(CHR))

  # Step 2: Sort
  df <- df %>% arrange(as.numeric(CHR), BP)

  # Step 3: Chromosome summary
  df_chr <- df %>%
    group_by(CHR) %>%
    summarise(max_bp = max(BP, na.rm = TRUE), .groups = "drop") %>%
    arrange(as.numeric(CHR)) %>%
    mutate(cumulative = cumsum(max_bp) - max_bp)

  # Step 4: Merge
  df <- df %>%
    left_join(df_chr, by = "CHR") %>%
    filter(!is.na(cumulative)) %>%
    mutate(BP_cum = BP + cumulative)

  # Step 5: Axis labels
  axis_df <- df %>%
    group_by(CHR) %>%
    summarise(center = (min(BP_cum) + max(BP_cum)) / 2, .groups = "drop")

  # Step 6: Color map
  chroms <- sort(unique(df$CHR))
  chrom_colors <- rep(c("grey", "skyblue"), length.out = length(chroms))
  names(chrom_colors) <- chroms

  # Step 7: Manhattan Plot
  ggplot(df, aes(x = BP_cum, y = -log10(.data[[pval_col]]))) +
    geom_point(aes(color = CHR), alpha = 0.75, size = 1.3) +
    scale_color_manual(values = chrom_colors) +
    scale_x_continuous(label = axis_df$CHR, breaks = axis_df$center) +
    labs(x = "Chromosome", 
         y = expression(-log[10](p-value)), 
         title = plot_title) +
    geom_hline(yintercept = -log10(pval_cutoff), linetype = "dashed", color = "red") +
    theme_minimal() +
    theme(legend.position = "none",
          panel.border = element_blank(),
          panel.grid.major.x = element_blank())
}

```

```{r testing function, echo = TRUE, message = FALSE, warning = FALSE}
generate_manhattan_plot(df3, pval_cutoff = 0.05, plot_title = "Manhattan Plot of Raw P-values for 100,000 SNPs")
```

However, after doing some research, I learned there are already existing functions that create Manhattan plots (`qqman` library), so I will be using this function to create my Manhattan plots instead [3].

```{r qqman 100k Bonferroni, echo = TRUE, message = FALSE, warning = FALSE}
df3_clean <- df3 %>%
  filter(!is.na(P))
manhattan(df3_clean, chr = "#CHROM", bp = "POS", snp = "ID", p = "P", suggestiveline = FALSE,
          genomewideline = -log10(2.7e-09), ylim = c(0, 10)) 
title(main = "Manhattan Plot of Raw P-values for 100,000 SNPs Bonferroni")
abline(h = -log10(9.5e-09), col = "darkgreen", lty = 3)

```

```{r qqman ch6 0.05, echo = TRUE, message = FALSE, warning = FALSE}

ch6_clean <- ch6 %>%
  filter(!is.na(P))
manhattan(ch6_clean, chr = "#CHROM", bp = "POS", snp = "ID", p = "P", highlight = "rs4254998",
          genomewideline = -log10(0.05), ylim = c(0, 6)) 
title(main = "Manhattan Plot of Raw P-values for Chr. 6 SNPs p = 0.05")
```
# QQ plots

I tried to create my code to create a QQ plot before I realized that there already is one in `qqman`

```{r QQ plot for subset}
pvals <- df3$P
pvals <- pvals[!is.na(pvals)]

n <- length(pvals)

expected <- -log10(ppoints(n))
observed <- -log10(sort(pvals))

plot(expected, observed,
     pch = 19,
     col = rgb(0, 0, 0, 0.5),
     cex = 0.6,
     xlab = "Expected -log10(p)",
     ylab = "Observed -log10(p)",
     main = "QQ Plot of GWAS P-values")

abline(0, 1, col = "red", lwd = 2)


```

```{r qqplot 100k, echo = TRUE, message = FALSE, warning = FALSE}
qq(df3_clean$P, main = "QQ Plot of GWAS P-values for 100k SNPs")
```

```{r qqplot chr6, echo = TRUE, message = FALSE, warning = FALSE}
qq(ch6_clean$P, main = "QQ Plot of GWAS P-values for Chr. 6")
```

# Various FDR methods

Now I will be trying different FDR methods, from most to least conservative.

## Benjamini-Yekutieli

Out of the p-value adjustment methods, Benjamini Yekuteli is the most conservative, so I will try it first. R has a `p.adjust` function that can automatically apply the BY method.

```{r Benjamini-Yekutieli test, echo = TRUE, message = FALSE, warning = FALSE}

df3_clean$P_BY <- p.adjust(df3_clean$P, method = "BY")

# Summary stats of BY-adjusted p-values
summary(df3_clean$P_BY)

# Filter significant results under BY 
df3_by_sig <- df3_clean %>% filter(P_BY < 0.05)

manhattan(df3_clean, chr = "#CHROM", bp = "POS", snp = "ID", p = "P_BY", suggestiveline = FALSE, ylim = c(0,1)) 
title(main = "Manhattan Plot of BY adjusted P-values for 100,000 SNPs")
```

I cannot visualize the BY-adjusted p-values using my Manhattan Plot. In this case, I can thankfully modify and re-use my plotting function from earlier:

```{r plot function, echo = TRUE, message = FALSE, warning = FALSE}
generate_plot <- function(df, 
                                    chrom_col = "#CHROM", 
                                    pos_col = "POS", 
                                    pval_col = "P", 
                                    plot_title = "Plot") {

  # Step 1: Normalize CHR and BP
  df <- df %>%
    mutate(CHR = gsub("chr", "", .data[[chrom_col]], ignore.case = TRUE),
           CHR = gsub("[^0-9XYMT]", "", CHR),
           CHR = as.character(CHR),
           BP = as.numeric(.data[[pos_col]])) %>%
    filter(!is.na(BP) & !is.na(CHR))

  # Step 2: Sort
  df <- df %>% arrange(as.numeric(CHR), BP)

  # Step 3: Chromosome summary
  df_chr <- df %>%
    group_by(CHR) %>%
    summarise(max_bp = max(BP, na.rm = TRUE), .groups = "drop") %>%
    arrange(as.numeric(CHR)) %>%
    mutate(cumulative = cumsum(max_bp) - max_bp)

  # Step 4: Merge
  df <- df %>%
    left_join(df_chr, by = "CHR") %>%
    filter(!is.na(cumulative)) %>%
    mutate(BP_cum = BP + cumulative)

  # Step 5: Axis labels
  axis_df <- df %>%
    group_by(CHR) %>%
    summarise(center = (min(BP_cum) + max(BP_cum)) / 2, .groups = "drop")

  # Step 6: Color map
  chroms <- sort(unique(df$CHR))
  chrom_colors <- rep(c("grey", "skyblue"), length.out = length(chroms))
  names(chrom_colors) <- chroms

  # Step 7: Plot
  ggplot(df, aes(x = BP_cum, y = .data[[pval_col]])) +
    geom_point(aes(color = CHR), alpha = 0.75, size = 1.3) +
    scale_color_manual(values = chrom_colors) +
    scale_x_continuous(label = axis_df$CHR, breaks = axis_df$center) +
    ylim(0,1)+
    labs(x = "Chromosome", 
         y = 'p-value', 
         title = plot_title) +
    theme_minimal() +
    theme(legend.position = "none",
          panel.border = element_blank(),
          panel.grid.major.x = element_blank())
}

```

```{r BY plot test, echo = TRUE, message = FALSE, warning = FALSE}
generate_plot(df3_clean, pval_col = "P_BY", plot_title = "Plot of BY adjusted P-values for 100,000 SNPs")
```

Using my new and improved plotting function, we can see that because the Benjamini-Yekutieli method is so conservative, all of the p-values were adjusted to 1.

## Benjamini-Hochberg

Now I will try adjust my p-values using the Benjamini-Hochberg method.

```{r Benjamini-Hochberg test, echo = TRUE, message = FALSE, warning = FALSE}
# Adjusting p_values using BH
df3_clean$P_BH <- p.adjust(df3_clean$P, method = "BH")

#Summary stats of adjusted p-values
summary(df3_clean$P_BH)

df3_bh_sig <- df3_clean %>% filter(P_BH < 0.05) #there are no significant p-values after BH adjustment 
df3_clean$log10_P_BH <- -log10(df3_clean$P_BH)

manhattan(df3_clean, chr = "#CHROM", bp = "POS", snp = "ID", p = "P_BH", suggestiveline = FALSE, ylim = c(0, 0.005)) 
title(main = "Plot of BH adjusted P-values for 100,000 SNPs")


```


```{r BH plot test, echo = TRUE, message = FALSE, warning = FALSE}
generate_plot(df3_clean, pval_col = "P_BH", plot_title = "Plot of BH adjusted P-values for 100,000 SNPs")
```

## Benjamini-Krieger-Yekutieli 

Now I will try to use the Benjamini-Krieger-Yekutieli method in the `mutoss` package [4]: 
```{r mutoss BKY, eval = FALSE}
mutoss::loadMethod("BKY")


bky_result <- mutoss::runMethod("BKY", list(pValues = df3_clean$P, alpha = 0.05))
```

Unfortunately, I could not get the `mutoss` package's implementation of BKY to work, so I will instead follow the original 2006 paper [5], which describes how to implement the BKY method:

```{r BKY implementation}
#BYK function
bky_adjust <- function(p, alpha = 0.05) {
  m <- length(p)
  p_order <- order(p)
  p_sorted <- p[p_order]
  k <- m:1
  c_m <- sum(1 / (1:m))
  
  thresh <- (k / m) * (alpha / (1 + alpha)) * (1 / c_m)
  test <- p_sorted <= thresh
  max_k <- if (any(test)) max(which(test)) else 0
  
  adjusted <- rep(1, m)
  if (max_k > 0) {
    adjusted[p_order[1:max_k]] <- pmin(1, thresh[max_k])
  }
  
  return(adjusted)
}

# Applying BKY to the data

df3_clean$P_BKY <- bky_adjust(df3_clean$P, alpha = 0.05)
df3_bky_sig <- df3_clean %>% filter(P_BKY < 0.05)

summary(df3_bky_sig$P_BKY)

# Plot
manhattan(df3_clean, chr = "#CHROM", bp = "POS", snp = "ID", p = "P_BKY",
          suggestiveline = FALSE)
title(main = "Plot of BKY Adjusted P-values for 100,000 SNPs")

```

```{r BYK plot test, echo = TRUE, message = FALSE, warning = FALSE}
generate_plot(df3_clean, pval_col = "P_BKY", plot_title = "Plot of BKY adjusted P-values for 100,000 SNPs")
```
This time, I was able to isolate around 300 significant SNPs using the BYK method. However, they were all the same p-value. Therefore, while BYK is able to separate  
## Storey-Tibshirani (q-value)

Now I will be adjusting my p-values using the Storey-Tibshirani method [6]. Thankfully, there is a package in R that was designed in collaboration with the creators of this method, the `qvalue` package. I followed the documentation of the `qvalue` package to use the `qvalue()` method and other methods on my data [7].

```{r, echo = TRUE, message = FALSE, warning = FALSE}
qobj <- qvalue(p = df3_clean$P)  # estimating pi_0 and q-values
df3_clean$q_value <- qobj$qvalues

df3_q_sig <- df3_clean %>% filter(q_value < 0.05)
nrow(df3_q_sig)  

qobj$pi0

```

Unfortunately, I was not able to actually find any significant q_values. My pi_0 was 0.971, which means that 97.1% of the tested SNPs are estimated to be null.

```{r best BKYs, echo = TRUE, message = FALSE, warning = FALSE}
top_bky <- df3_clean %>%
  arrange(P) %>%
  slice(1:50) %>%
  select(`#CHROM`, POS, ID, P, P_BKY)

```

Taking a second look at the p-values that were marked as being signficant from BYK, they appear to be randomly clustered throughout the genome. However, the second most significant SNP is located on chromosome 6, the same chromosome as the HLA gene cluster that was found to be significant in the original study. So, I think to conclude, I will try to figure out where this SNP is located and its potential biological function.

SNP POS: 129948488
#CHROM: 6

I used the NCBI Human Genome Data Viewer [8] to figure out the genomic context of chr6:129948488. This SNP lies within an intron region of L3MBTL3, situated between a nearby HLA class II gene and an uncharacterized gene. L3MBTL3  has been implicated in several GWAS as influencing hematopoietic traits and immunoglobulin A (IgA) levels. Variants in L3MBTL3 have been associated with natural variation in IgA concentrations, suggesting a potential role in humoral immune regulation. These findings suggest that SNPs in or near L3MBTL3 could indirectly modulate immune responses, potentially by influencing the development or regulation of immune effector cells [9].

Therefore, while I was not able to identify a clear enrichment of significant SNPs in known immune loci across the genome, I was able to pinpoint at least one biologically plausible candidate. Its proximity to the HLA region and its known association with immune-related traits make it a promising lead for further investigation. Further analysis of the SNPs that were flagged as being significant by the BKY method should be looked into, as they may represent novel loci of biological relevance that have not yet been characterized in the context of immune response by the original study.


#Misc graphs


```{r normal distribution testing, echo = TRUE, message = FALSE, warning = FALSE}
df3_clean$logP <- -log10(df3_clean$P)


ggplot(df3_clean, aes(x = -log10(P))) +
  geom_histogram(bins = 50, fill = "skyblue", color = "white") +
  labs(title = "Distribution of –log10(P-values)",
       x = "–log10(P-value)", y = "Count") +xlim(0, 4) 
  theme_minimal()


ggplot(df3_clean, aes(x = -log10(P))) +
  geom_histogram(bins = 50, fill = "skyblue", color = "white") +
  labs(title = "Distribution of –log10(P-values)",
       x = "–log10(P-value)", y = "Count") +xlim(2, 4) 
  theme_minimal()

```

```{r normal dist curve, echo = TRUE, message = FALSE, warning = FALSE}
#To create figure in slide deck
x <- seq(-4, 4, length.out = 1000)
y <- dnorm(x)

df_norm <- data.frame(x = x, y = y)

z_cutoff <- qnorm(0.95)  

shade_df <- subset(df_norm, x > z_cutoff)


ggplot(df_norm, aes(x, y)) +
  geom_line(color = "black", size = 1) +  # Normal curve
  geom_area(data = shade_df, aes(x, y), fill = "skyblue", alpha = 0.6) + 
  geom_vline(xintercept = z_cutoff, color = "red", linetype = "dashed", size = 1) +  
  labs(
    title = "Standard Normal Distribution with One-Sided p = 0.05 Cutoff",
    x = "Z-score",
    y = "Density"
  ) +
  theme_minimal()

```

# References

[1] https://www.milieuinterieur.fr/en/about-us/the-milieu-interieur/

[2]Scepanovic, P., Alanio, C., Hammer, C., et al. (2018). Human genetic variants and age are the strongest predictors of humoral immune responses to common pathogens and vaccines. Genome Medicine, 10, 59. https://doi.org/10.1186/s13073-018-0568-8

[3] https://www.rdocumentation.org/packages/qqman/versions/0.1.2/topics/manhattan

[4] https://search.r-project.org/CRAN/refmans/mutoss/html/multiple.down.html

[5] Benjamini, Y., Krieger, A. M., & Yekutieli, D. (2006). Adaptive Linear Step-up Procedures That Control the False Discovery Rate. Biometrika, 93(3), 491–507. https://doi.org/10.1093/biomet/93.3.491 

[6] Storey JD, Tibshirani R. Statistical significance for genomewide studies. Proc Natl Acad Sci U S A. 2003 Aug 5;100(16):9440-5. doi: 10.1073/pnas.1530509100. Epub 2003 Jul 25. PMID: 12883005; PMCID: PMC170937.

[7] https://www.rdocumentation.org/packages/qvalue/versions/2.4.2/topics/qvalue

[8] https://www.ncbi.nlm.nih.gov/gdv/

[9] Arai S, Miyazaki T. Impaired maturation of myeloid progenitors in mice lacking novel Polycomb group protein MBT-1. EMBO J. 2005 May 18;24(10):1863-73. doi: 10.1038/sj.emboj.7600654 
