---
title: "Arkesh Das CMSE 410 Semester Project"
author: "Arkesh Das"
date: "03/30/2025"
output:
  pdf_document:
    latex_engine: xelatex
    keep_tex: true
    includes:
      in_header: preamble.tex
fontsize: 12pt
mainfont: Times New Roman
monofont: Courier New
linestretch: 2
---
# Applying different methods of controlling the False Discovery Rate to 

## Background 

### What is GWAS and FDR

### Et al

The data that I have chosen to analyze comes from a study that is part of Milieu Intérieur the project [1]. The Milieu Intérieur Project aims at 

Study Cohort (Milieu Intérieur)
Participants: 1000 healthy adults (500 men, 500 women), ages 20–69 (200 per decade).
Geographic/Ancestral Background: All had self-reported Metropolitan French origin (parents and grandparents born in continental France) to minimize genetic substructure.
Health Status: Individuals were stringently screened (e.g., no chronic infections, no ongoing hepatitis B/C, HIV-negative).
Sample Collection and Measurements
Blood Draw: Peripheral blood was collected into tubes containing lithium heparin (for plasma-based assays) and EDTA (for DNA extraction).
Immunoglobulin Measurements:
Total IgG, IgM, IgA, and IgE were measured from serum/plasma using clinical-grade turbidimetric tests.
Pathogen-Specific IgG: They assayed 15 different antigens from common viruses and bacteria (e.g., CMV, EBV, HSV-1/2, VZV, H. pylori, T. gondii, influenza A) plus vaccine-related antigens (measles, mumps, rubella, and hepatitis B). Each was measured via clinical-grade serologies, yielding both a seropositivity status and (for positives) a quantitative IgG level.
Genotyping and Genetic Analysis
Arrays: DNA was genotyped using (1) the Illumina HumanOmniExpress-24 (for ~700k SNPs) and (2) the HumanExome-12 (for ~245k exonic variants).
Imputation and Quality Control: The authors imputed to a reference panel (Haplotype Reference Consortium), resulting in ~5 million common variants for genome-wide association tests. They also analyzed variation in the HLA region (including HLA alleles and amino-acid positions) and KIR genes.
What They Were Looking For
Primary Goal: Understand the variability in humoral immune responses (who tests positive for each antigen, and at what antibody levels) and assess how age, sex, and host genetics (especially in the HLA region) shape these differences.
Analyses:
Logistic regressions for seropositivity (positive vs. negative).
Linear regressions for log-transformed antibody levels among seropositive donors.
Associations were tested genome-wide, with corrections for false discovery and potential confounders (age, sex, and other covariates).
Key Findings (High-Level)
Age and Sex: Strong predictors of whether a person was seropositive and at what level of IgG. Generally, older donors and women had higher rates of positivity and/or higher antibody titers for many antigens.
Genetics: Variants in the HLA class II region were significantly associated with IgG levels to EBV and rubella. Certain KIR–HLA combinations associated with total IgA levels.

# Loading in the Data

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message= FALSE, warning=TRUE)
knitr::opts_chunk$set(fig.width=12, fig.height=8) 

library(tidyverse)
library(tidyr)
library(dplyr)
library(ggplot2)
library(qqman)
library(mutoss)
```

# Reading in the Data and making dataframes

```{r dataframes}

#df will contain all of the data from the study that had MAF > 5%
#df2 is 1,000 snps, used to test code chunks before running on larger data frames
#df3 contains 100,000 random snps, used as an analogue for the entire data set
#ch6 contains the 354095 snps identified on chromosome 6

#reloading the 'df' dataframe takes a long time because of the number of observations 
df <- read.table("/Users/arkeshdas/Documents/CMSE 410/repos/HBV_HBc_GWAS_serostatus.txt", header = FALSE, sep = "", stringsAsFactors = FALSE)
colnames(df) <- c("#CHROM", "POS", "ID", "REF", "ALT", "ALT_FREQ", "TEST", "OBS_CT", "OR", "SE", "T_STAT", "P")
head(df)

df2 <- read.table("/Users/arkeshdas/Documents/CMSE 410/repos/HBV_HBc_GWAS_serostatus.txt", header = FALSE, sep = "", stringsAsFactors = FALSE, nrows = 1000)
colnames(df2) <- c("#CHROM", "POS", "ID", "REF", "ALT", "ALT_FREQ", "TEST", "OBS_CT", "OR", "SE", "T_STAT", "P")
head(df2)

set.seed(03302025)  # Setting seed for reproducibility for df3
df3 <- df[sample(nrow(df), 100000), ]
colnames(df3) <- c("#CHROM", "POS", "ID", "REF", "ALT", "ALT_FREQ", "TEST", "OBS_CT", "OR", "SE", "T_STAT", "P")
head(df3)

ch6 <- df %>% filter(`#CHROM` == 6)

colnames(ch6) <- c("#CHROM", "POS", "ID", "REF", "ALT", "ALT_FREQ", "TEST", "OBS_CT", "OR", "SE", "T_STAT", "P")
head(ch6)
```

# Creating Manhattan Plots

Because I will be making many Manhattan plots, I initially decided to create a function that I can pass parameters into rather than creating a Manhattan plot by hand each time.

```{r manhattan plot function}
generate_manhattan_plot <- function(df, 
                                    chrom_col = "#CHROM", 
                                    pos_col = "POS", 
                                    pval_col = "P", 
                                    plot_title = "Manhattan Plot", 
                                    pval_cutoff = 0.05) {

  # Step 1: Normalize CHR and BP
  df <- df %>%
    mutate(CHR = gsub("chr", "", .data[[chrom_col]], ignore.case = TRUE),
           CHR = gsub("[^0-9XYMT]", "", CHR),
           CHR = as.character(CHR),
           BP = as.numeric(.data[[pos_col]])) %>%
    filter(!is.na(BP) & !is.na(CHR))

  # Step 2: Sort
  df <- df %>% arrange(as.numeric(CHR), BP)

  # Step 3: Chromosome summary
  df_chr <- df %>%
    group_by(CHR) %>%
    summarise(max_bp = max(BP, na.rm = TRUE), .groups = "drop") %>%
    arrange(as.numeric(CHR)) %>%
    mutate(cumulative = cumsum(max_bp) - max_bp)

  # Step 4: Merge
  df <- df %>%
    left_join(df_chr, by = "CHR") %>%
    filter(!is.na(cumulative)) %>%
    mutate(BP_cum = BP + cumulative)

  # Step 5: Axis labels
  axis_df <- df %>%
    group_by(CHR) %>%
    summarise(center = (min(BP_cum) + max(BP_cum)) / 2, .groups = "drop")

  # Step 6: Color map
  chroms <- sort(unique(df$CHR))
  chrom_colors <- rep(c("grey", "skyblue"), length.out = length(chroms))
  names(chrom_colors) <- chroms

  # Step 7: Manhattan Plot
  ggplot(df, aes(x = BP_cum, y = -log10(.data[[pval_col]]))) +
    geom_point(aes(color = CHR), alpha = 0.75, size = 1.3) +
    scale_color_manual(values = chrom_colors) +
    scale_x_continuous(label = axis_df$CHR, breaks = axis_df$center) +
    labs(x = "Chromosome", 
         y = expression(-log[10](p-value)), 
         title = plot_title) +
    geom_hline(yintercept = -log10(pval_cutoff), linetype = "dashed", color = "red") +
    theme_minimal() +
    theme(legend.position = "none",
          panel.border = element_blank(),
          panel.grid.major.x = element_blank())
}

```

```{r testing function}
generate_manhattan_plot(df3, pval_cutoff = 0.05, plot_title = "Manhattan Plot of Raw P-values for 100,000 SNPs")
```

However, after doing some research, I learned there are already existing functions that create Manhattan plots (`qqman` library), so I will be using this function to create my Manhattan plots instead [2].

```{r qqman 100k Bonferroni}
df3_clean <- df3 %>%
  filter(!is.na(P))
manhattan(df3_clean, chr = "#CHROM", bp = "POS", snp = "ID", p = "P", suggestiveline = FALSE,
          genomewideline = -log10(2.7e-09), ylim = c(0, 10)) 
title(main = "Manhattan Plot of Raw P-values for 100,000 SNPs Bonferroni")
abline(h = -log10(9.5e-09), col = "darkgreen", lty = 3)

```

```{r qqman ch6 0.05}

ch6_clean <- ch6 %>%
  filter(!is.na(P))
manhattan(ch6_clean, chr = "#CHROM", bp = "POS", snp = "ID", p = "P", highlight = "rs4254998",
          genomewideline = -log10(0.05), ylim = c(0, 6)) 
title(main = "Manhattan Plot of Raw P-values for Chr. 6 SNPs p = 0.05")
```
# QQ plots

I tried to create my code to create a QQ plot before I realzed that there already is one in `qqman`

```{r QQ plot for subset}
pvals <- df3$P
pvals <- pvals[!is.na(pvals)]

n <- length(pvals)

expected <- -log10(ppoints(n))
observed <- -log10(sort(pvals))

plot(expected, observed,
     pch = 19,
     col = rgb(0, 0, 0, 0.5),
     cex = 0.6,
     xlab = "Expected -log10(p)",
     ylab = "Observed -log10(p)",
     main = "QQ Plot of GWAS P-values")

abline(0, 1, col = "red", lwd = 2)


```

```{r qqplot 100k}
qq(df3_clean$P, main = "QQ Plot of GWAS P-values for 100k SNPs")
```

```{r qqplot chr6}
qq(ch6_clean$P, main = "QQ Plot of GWAS P-values for Chr. 6")
```

# Various FDR methods


Now I will be trying different FDR methods

## Benjamini-Hochberg

```{r Benjamini-Hochberg test}
# Step 2: Adjust p-values using the Benjamini-Hochberg method
df2$P_adj <- p.adjust(df2$P, method = "BH")

# Step 3: Get a summary of adjusted p-values
summary(df2$P_adj)

# Step 4: Extract significant associations (adjusted p < 0.05)
significant_hits <- subset(df2, P_adj < 0.05)
# Alternatively:
# significant_hits <- df[df$P_adj < 0.05, ]

# Step 5: Sort significant hits by P_adj
significant_hits <- significant_hits[order(significant_hits$P_adj), ]
head(significant_hits)

```

## Benjamini-Yekutieli

## Benjamini-Krieger-Yekutieli 

## Storey-Tibshirani (q-value)

#Misc graphs


```{r normal distribution testing}
df3_clean$logP <- -log10(df3_clean$P)


ggplot(df3_clean, aes(x = -log10(P))) +
  geom_histogram(bins = 50, fill = "skyblue", color = "white") +
  labs(title = "Distribution of –log10(P-values)",
       x = "–log10(P-value)", y = "Count") +xlim(0, 4) 
  theme_minimal()


ggplot(df3_clean, aes(x = -log10(P))) +
  geom_histogram(bins = 50, fill = "skyblue", color = "white") +
  labs(title = "Distribution of –log10(P-values)",
       x = "–log10(P-value)", y = "Count") +xlim(2, 4) 
  theme_minimal()

```

```{r normal dist curve}
#To create figure in slide deck
x <- seq(-4, 4, length.out = 1000)
y <- dnorm(x)

df_norm <- data.frame(x = x, y = y)

z_cutoff <- qnorm(0.95)  

shade_df <- subset(df_norm, x > z_cutoff)


ggplot(df_norm, aes(x, y)) +
  geom_line(color = "black", size = 1) +  # Normal curve
  geom_area(data = shade_df, aes(x, y), fill = "skyblue", alpha = 0.6) + 
  geom_vline(xintercept = z_cutoff, color = "red", linetype = "dashed", size = 1) +  
  labs(
    title = "Standard Normal Distribution with One-Sided p = 0.05 Cutoff",
    x = "Z-score",
    y = "Density"
  ) +
  theme_minimal()

```

# References

[1] https://www.milieuinterieur.fr/en/about-us/the-milieu-interieur/

[2] https://www.rdocumentation.org/packages/qqman/versions/0.1.2/topics/manhattan

[3] Benjamini, Y., Krieger, A. M., & Yekutieli, D. (2006). Adaptive Linear Step-up Procedures That Control the False Discovery Rate. Biometrika, 93(3), 491–507. http://www.jstor.org/stable/20441303

[4] Storey JD, Tibshirani R. Statistical significance for genomewide studies. Proc Natl Acad Sci U S A. 2003 Aug 5;100(16):9440-5. doi: 10.1073/pnas.1530509100. Epub 2003 Jul 25. PMID: 12883005; PMCID: PMC170937.

[5]

